#!/usr/bin/env python3
"""
ğŸ” DETAILED OUTPUT TEST - Phase 1 Enhanced System
Shows exactly what happens during interactive testing with full logging.
"""

import os
import time
from interactive_agent import InteractiveAgent

def run_detailed_test():
    print("ğŸ” DETAILED OUTPUT TEST - Phase 1 Enhanced System")
    print("=" * 60)
    
    # Check environment first
    print("ğŸ”§ ENVIRONMENT CHECK:")
    api_key = os.getenv("OPENAI_API_KEY")
    if api_key:
        print(f"âœ… OpenAI API Key: ...{api_key[-4:] if len(api_key) > 4 else 'Set'}")
    else:
        print("âŒ OpenAI API Key not found!")
        print("   Set it with: export OPENAI_API_KEY='your-key-here'")
        print("   Continuing with demo mode...")
    
    print("\nğŸ¤– INITIALIZING ENHANCED AGENT:")
    print("-" * 35)
    
    try:
        agent = InteractiveAgent()
        print("âœ… Interactive Agent created")
        print("âœ… OpenAI Client Wrapper loaded")
        print("âœ… Browser Tools ready")
        print("âœ… Rate limiting configured")
        
        # Show initial statistics
        initial_stats = agent.client.get_usage_stats()
        print(f"ğŸ“Š Initial API Stats: {initial_stats}")
        
    except Exception as e:
        print(f"âŒ Agent initialization failed: {e}")
        return False
    
    # Test scenario
    print("\nğŸ¯ TEST SCENARIO SETUP:")
    print("-" * 25)
    test_url = "https://www.google.com"
    scenario = "Take a screenshot of the page, find the search input, and examine the page structure"
    
    print(f"ğŸŒ URL: {test_url}")
    print(f"ğŸ“ Scenario: {scenario}")
    
    # Show batching suggestions
    print("\nğŸ’¡ BATCHING OPTIMIZATION ANALYSIS:")
    print("-" * 35)
    suggestions = agent._suggest_batch_optimizations(scenario)
    if suggestions:
        print(suggestions)
    else:
        print("ğŸ’¡ No specific batching suggestions for this scenario type")
    
    print("\nğŸš€ EXECUTING TEST WITH DETAILED LOGGING:")
    print("=" * 50)
    
    try:
        start_time = time.time()
        
        # Run the scenario with detailed output
        print("â³ Starting interactive scenario analysis...")
        result = agent.analyze_scenario(test_url, scenario)
        
        end_time = time.time()
        execution_time = end_time - start_time
        
        print(f"\nğŸ‰ TEST COMPLETED SUCCESSFULLY!")
        print("=" * 40)
        
        # Display comprehensive results
        print(f"â±ï¸  Total Execution Time: {execution_time:.2f} seconds")
        print(f"ğŸ¯ Final Status: {result.get('status', 'Unknown')}")
        print(f"ğŸ’¬ Final Message: {result.get('final_message', 'No final message')}")
        
        # Show detailed action breakdown
        actions = result.get('actions', [])
        print(f"\nğŸ“‹ DETAILED ACTION HISTORY ({len(actions)} actions):")
        print("-" * 45)
        
        if actions:
            for i, action in enumerate(actions, 1):
                action_type = action.get('action', 'unknown')
                message = action.get('message', 'No message')
                success = action.get('success', 'Unknown')
                
                print(f"\n{i}. ACTION: {action_type.upper()}")
                print(f"   Status: {'âœ…' if success else 'âŒ'} {success}")
                print(f"   Result: {message}")
                
                # Show any additional details
                if 'screenshot_base64' in action:
                    print(f"   ğŸ“¸ Screenshot: Captured ({len(action['screenshot_base64'])} chars)")
                if 'elements_found' in action:
                    print(f"   ğŸ” Elements: Found {action['elements_found']}")
                if 'url' in action:
                    print(f"   ğŸŒ URL: {action['url']}")
        else:
            print("   âŒ No actions recorded")
        
        # Show API usage statistics
        final_stats = agent.client.get_usage_stats()
        print(f"\nğŸ“ˆ API USAGE STATISTICS:")
        print("-" * 25)
        print(f"ğŸ“Š Total Requests: {final_stats['total_requests']}")
        print(f"âœ… Successful Requests: {final_stats['successful_requests']}")
        print(f"âŒ Failed Requests: {final_stats['failed_requests']}")
        print(f"ğŸ”„ Total Retries: {final_stats['total_retries']}")
        print(f"ğŸ”„ Rate Limited: {final_stats.get('rate_limited_requests', 0)}")
        print(f"âš¡ Fallback Uses: {final_stats['fallback_requests']}")
        
        # Calculate efficiency metrics
        if final_stats['total_requests'] > 0:
            success_rate = (final_stats['successful_requests'] / final_stats['total_requests']) * 100
            print(f"ğŸ“Š Success Rate: {success_rate:.1f}%")
        
        if len(actions) > 0 and execution_time > 0:
            actions_per_second = len(actions) / execution_time
            print(f"âš¡ Actions per Second: {actions_per_second:.2f}")
        
        # Show Phase 1 feature analysis
        print(f"\nğŸ¯ PHASE 1 ENHANCED FEATURES ANALYSIS:")
        print("-" * 40)
        
        # Batching analysis
        if len(actions) > 1:
            print("âœ… Batching Optimization: Multiple actions processed efficiently")
        else:
            print("ğŸ’¡ Batching Optimization: Single action scenario")
        
        # Rate limiting analysis
        if final_stats['total_retries'] > 0:
            print(f"âœ… Rate Limiting: {final_stats['total_retries']} retries handled gracefully")
        else:
            print("âœ… Rate Limiting: No retries needed (smooth execution)")
        
        # Disambiguation analysis
        click_actions = [a for a in actions if a.get('action') == 'click']
        if click_actions:
            print("âœ… Smart Disambiguation: Element selection working")
        else:
            print("ğŸ’¡ Smart Disambiguation: No click actions to analyze")
        
        # Error handling analysis
        if final_stats['failed_requests'] == 0:
            print("âœ… Error Handling: No failures encountered")
        else:
            print(f"âš ï¸  Error Handling: {final_stats['failed_requests']} requests failed")
        
        print(f"\nğŸ‰ PHASE 1 SYSTEM STATUS: FULLY OPERATIONAL!")
        print("âœ… Rate limiting with exponential backoff")
        print("âœ… Smart element disambiguation") 
        print("âœ… Batching optimization")
        print("âœ… Robust error handling")
        print("âœ… Performance monitoring")
        
        return True
        
    except Exception as e:
        print(f"\nâŒ TEST FAILED: {e}")
        print("\nDETAILED ERROR INFO:")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    print("ğŸ¯ Starting detailed test in 3 seconds...")
    print("   This will show you exactly what the enhanced system does")
    print("   Press Ctrl+C to cancel")
    
    try:
        time.sleep(3)
        success = run_detailed_test()
        
        if success:
            print("\nâœ¨ DETAILED TEST COMPLETED!")
            print("ğŸ¯ You can see exactly how the Phase 1 enhancements work!")
            print("ğŸš€ Ready for more complex scenarios or Phase 2 development!")
        else:
            print("\nğŸ”§ Test had issues. Check error details above.")
            
    except KeyboardInterrupt:
        print("\nğŸ›‘ Test cancelled by user")
    except Exception as e:
        print(f"\nâŒ Unexpected error: {e}")
