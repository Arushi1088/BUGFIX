#!/usr/bin/env python3
"""
ğŸ§ª PHASE 1 ENHANCED UX TESTING SYSTEM - COMPLETE TEST
=====================================================
This test demonstrates all Phase 1 features:
âœ… Rate limiting with exponential backoff
âœ… Smart element disambiguation 
âœ… Batching optimization
âœ… Robust error handling
"""

import os
import time
from interactive_agent import InteractiveAgent

def run_comprehensive_test():
    """Run a comprehensive test of the enhanced UX testing system."""
    
    print("ğŸ§ª PHASE 1 ENHANCED UX TESTING SYSTEM - COMPREHENSIVE TEST")
    print("=" * 65)
    
    # Check environment
    print("ğŸ” Environment Check:")
    api_key = os.getenv("OPENAI_API_KEY")
    if api_key:
        print(f"âœ… OpenAI API Key: ...{api_key[-4:] if len(api_key) > 4 else 'Set'}")
    else:
        print("âŒ OpenAI API Key not found!")
        print("   Run: export OPENAI_API_KEY='your-key-here'")
        return False
    
    print("âœ… Environment ready\n")
    
    # Initialize agent
    print("ğŸ¤– Initializing Enhanced Agent...")
    try:
        agent = InteractiveAgent()
        print("âœ… Agent initialized with Phase 1 enhancements")
    except Exception as e:
        print(f"âŒ Agent initialization failed: {e}")
        return False
    
    # Test scenarios with increasing complexity
    test_scenarios = [
        {
            "name": "Basic Search Test",
            "url": "https://www.google.com",
            "scenario": "Search for 'artificial intelligence' and examine the results",
            "expected_features": ["batching suggestions", "find_elements â†’ screenshot optimization"]
        },
        {
            "name": "GitHub Repository Search",
            "url": "https://github.com", 
            "scenario": "Find the search functionality and search for 'python machine learning'",
            "expected_features": ["disambiguation if multiple search elements", "navigation batching"]
        },
        {
            "name": "E-commerce Product Search",
            "url": "https://www.amazon.com",
            "scenario": "Test the product search by looking for 'laptop computers'",
            "expected_features": ["form field optimization", "rate limiting resilience"]
        }
    ]
    
    print(f"\nğŸ¯ Running {len(test_scenarios)} Test Scenarios:")
    print("-" * 50)
    
    all_results = []
    
    for i, test in enumerate(test_scenarios, 1):
        print(f"\nğŸ“ Test {i}: {test['name']}")
        print(f"ğŸŒ URL: {test['url']}")
        print(f"ğŸ“‹ Scenario: {test['scenario']}")
        print(f"ğŸ” Expected Features: {', '.join(test['expected_features'])}")
        
        # Show batching suggestions
        print(f"\nğŸ’¡ Batching Optimization Analysis:")
        suggestions = agent._suggest_batch_optimizations(test['scenario'])
        if suggestions:
            print(suggestions)
        else:
            print("ğŸ’¡ No specific batching suggestions for this scenario type")
        
        print(f"\nğŸš€ Executing Test {i}...")
        print("-" * 30)
        
        try:
            start_time = time.time()
            
            # Run the actual test
            result = agent.analyze_scenario(test['url'], test['scenario'])
            
            end_time = time.time()
            execution_time = end_time - start_time
            
            # Analyze results
            print(f"\nâœ… Test {i} Completed Successfully!")
            print(f"â±ï¸  Execution Time: {execution_time:.2f} seconds")
            print(f"ğŸ“Š Actions Taken: {len(result.get('actions', []))}")
            print(f"ğŸ¯ Status: {result.get('status', 'Unknown')}")
            
            # Show action summary
            actions = result.get('actions', [])
            if actions:
                print(f"\nğŸ“‹ Action Summary:")
                for j, action in enumerate(actions[-3:], 1):  # Show last 3 actions
                    action_type = action.get('action', 'unknown')
                    message = action.get('message', 'No message')[:50] + "..."
                    print(f"   {j}. {action_type}: {message}")
            
            # Show API usage statistics
            stats = agent.client.get_usage_stats()
            print(f"\nğŸ“ˆ API Statistics for Test {i}:")
            print(f"   â€¢ Total Requests: {stats['total_requests']}")
            print(f"   â€¢ Successful: {stats['successful_requests']}")
            print(f"   â€¢ Retries: {stats['total_retries']}")
            print(f"   â€¢ Fallbacks: {stats['fallback_requests']}")
            
            all_results.append({
                'test': test['name'],
                'success': True,
                'execution_time': execution_time,
                'actions': len(actions),
                'stats': stats
            })
            
        except Exception as e:
            print(f"âŒ Test {i} Failed: {e}")
            all_results.append({
                'test': test['name'],
                'success': False,
                'error': str(e)
            })
        
        print(f"\n{'='*50}")
        
        # Wait between tests to avoid rate limiting
        if i < len(test_scenarios):
            print("â³ Waiting 5 seconds before next test...")
            time.sleep(5)
    
    # Final summary
    print(f"\nğŸ‰ COMPREHENSIVE TEST SUMMARY")
    print("=" * 50)
    
    successful_tests = sum(1 for r in all_results if r['success'])
    total_tests = len(all_results)
    
    print(f"ğŸ“Š Test Results: {successful_tests}/{total_tests} successful")
    
    if successful_tests > 0:
        total_actions = sum(r.get('actions', 0) for r in all_results if r['success'])
        avg_time = sum(r.get('execution_time', 0) for r in all_results if r['success']) / successful_tests
        
        print(f"âš¡ Performance:")
        print(f"   â€¢ Total Actions: {total_actions}")
        print(f"   â€¢ Average Time: {avg_time:.2f} seconds per test")
        
        # Combined statistics
        if hasattr(agent, 'client'):
            final_stats = agent.client.get_usage_stats()
            print(f"ğŸ“ˆ Overall API Usage:")
            print(f"   â€¢ Total Requests: {final_stats['total_requests']}")
            print(f"   â€¢ Success Rate: {final_stats['successful_requests']}/{final_stats['total_requests']}")
            print(f"   â€¢ Total Retries: {final_stats['total_retries']}")
            print(f"   â€¢ Fallback Uses: {final_stats['fallback_requests']}")
    
    print(f"\nğŸš€ PHASE 1 FEATURES DEMONSTRATED:")
    print("âœ… Rate limiting with exponential backoff and fallbacks")
    print("âœ… Smart element disambiguation with multiple strategies")
    print("âœ… Batching optimization for reduced API calls")
    print("âœ… Robust error handling and recovery")
    print("âœ… Performance monitoring and statistics")
    
    if successful_tests == total_tests:
        print(f"\nğŸ‰ ALL TESTS PASSED! Phase 1 system is working perfectly!")
        print("ğŸš€ Ready for Phase 2 implementation!")
    else:
        print(f"\nâš ï¸  {total_tests - successful_tests} tests had issues. Check logs above.")
    
    return successful_tests == total_tests

if __name__ == "__main__":
    print("ğŸ¯ Starting comprehensive test in 3 seconds...")
    print("   Press Ctrl+C to cancel")
    
    try:
        time.sleep(3)
        success = run_comprehensive_test()
        
        if success:
            print("\nâœ¨ Test completed successfully!")
            print("ğŸ’¡ Try the web interface: python3 app.py â†’ http://localhost:5006")
        else:
            print("\nğŸ”§ Some tests failed. Check error messages above.")
            
    except KeyboardInterrupt:
        print("\nğŸ›‘ Test cancelled by user")
    except Exception as e:
        print(f"\nâŒ Test suite error: {e}")
        print("ğŸ’¡ Try: python3 simple_test_runner.py for basic checks")
